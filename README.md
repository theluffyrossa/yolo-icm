
# YOLO-ICM: Sistema Integrado de Detec√ß√£o de Objetos e Gera√ß√£o de Resumos de Imagens


Este reposit√≥rio cont√©m um sistema completo que integra o modelo de detec√ß√£o de objetos YOLO (You Only Look Once) com ICM (Image Caption Model) para criar uma solu√ß√£o que n√£o apenas detecta objetos em imagens e v√≠deos, mas tamb√©m gera descri√ß√µes textuais automaticamente.

## üåü Recursos

- **M√∫ltiplas Fontes de Entrada**:
  - üìπ Webcam em tempo real
  - üé¨ Streaming de v√≠deos do YouTube
  - üñºÔ∏è Upload de imagens est√°ticas

- **Detec√ß√£o Avan√ßada de Objetos**:
  - Identifica√ß√£o em tempo real usando YOLOv4
  - Visualiza√ß√£o com caixas delimitadoras coloridas
  - Classifica√ß√£o de objetos em mais de 80 categorias

- **Gera√ß√£o Autom√°tica de Descri√ß√µes**:
  - Resumos textuais do conte√∫do das imagens usando BLIP
  - An√°lise contextual das cenas detectadas
  - Atualiza√ß√£o din√¢mica das descri√ß√µes

- **Armazenamento Inteligente**:
  - Salvamento autom√°tico de detec√ß√µes relevantes
  - Organiza√ß√£o por timestamp
  - Exporta√ß√£o de resumos textuais e imagens processadas

## üìã Pr√©-requisitos

- Python 3.7+ 
- Bibliotecas principais:
  ```
  opencv-python >= 4.5.0
  numpy >= 1.19.0
  torch >= 1.8.0
  transformers >= 4.12.0
  pillow >= 8.0.0
  tkinter (inclu√≠do na maioria das instala√ß√µes Python)
  ```

- Para streaming do YouTube:
  ```
  streamlink >= 3.0.0
  ```

- Espa√ßo em disco: ~300MB para modelos

## üöÄ Instala√ß√£o

1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/theluffyrossa/yolo-icm.git
   cd yolo-icm
   ```

2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   pip install opencv-python numpy tkinter pillow torch transformers
   ```

3. Execute o sistema:
   ```bash
   python yolo_icm_system.py
   ```

Na primeira execu√ß√£o, o sistema baixar√° automaticamente os modelos necess√°rios (~250MB para YOLOv4 e ~50MB para BLIP).

## üíª Uso

### Interface Gr√°fica

Ap√≥s a inicializa√ß√£o, voc√™ ver√° a interface principal com as seguintes op√ß√µes:

- **Iniciar Webcam**: Inicia a detec√ß√£o usando a c√¢mera do computador
- **Iniciar YouTube**: Conecta-se ao streaming de v√≠deo definido
- **Carregar Imagem**: Abre um seletor de arquivos para processar imagens est√°ticas
- **Parar**: Interrompe o processamento atual

### Personalizando o Streaming

Para mudar a fonte de v√≠deo do YouTube, edite a constante `YOUTUBE_URL` no in√≠cio do arquivo:

```python
YOUTUBE_URL = "https://www.youtube.com/watch?v=SuaURL"
```

### Resultados

Os resultados s√£o salvos no diret√≥rio `detections/` organizado por timestamps:

```
detections/
‚îú‚îÄ‚îÄ 20250417_081530/
‚îÇ   ‚îú‚îÄ‚îÄ detection.jpg    # Imagem com objetos detectados
‚îÇ   ‚îî‚îÄ‚îÄ summary.txt      # Lista de objetos e descri√ß√£o
‚îú‚îÄ‚îÄ 20250417_081542/
...
```

## üß† Como Funciona

### Arquitetura do Sistema

O sistema opera em tr√™s camadas principais:

1. **Entrada de Dados**: Captura de frames de diversas fontes
2. **Processamento**: 
   - YOLO processa cada frame para detectar objetos
   - ICM (BLIP) gera descri√ß√µes baseadas no conte√∫do visual
3. **Sa√≠da**: Visualiza√ß√£o e armazenamento dos resultados

### Fluxo de Processamento

```
Captura ‚Üí Pr√©-processamento ‚Üí Detec√ß√£o YOLO ‚Üí Gera√ß√£o de Descri√ß√£o ‚Üí Visualiza√ß√£o ‚Üí Armazenamento
```

### Componentes Principais

- **YOLOv4**: Implementado via OpenCV DNN para detec√ß√£o eficiente
- **BLIP**: Modelo de transformer multimodal para gera√ß√£o de legendas
- **Interface Tkinter**: Para intera√ß√£o amig√°vel com o usu√°rio

## üìä Desempenho

O desempenho varia de acordo com o hardware dispon√≠vel:

| Configura√ß√£o | FPS (apenas YOLO) | FPS (YOLO + ICM) |
|--------------|-------------------|------------------|
| CPU (i5 ou similar) | 8-15 | 5-10 |
| GPU (NVIDIA GTX/RTX) | 25-45 | 15-30 |

*A gera√ß√£o de resumos ICM √© executada a cada 10 segundos para manter o desempenho.

## üîß Personaliza√ß√£o

### Ajustando Par√¢metros de Detec√ß√£o

Para modificar o limiar de confian√ßa da detec√ß√£o, altere o valor em:

```python
if confidence > 0.5:  # Altere para um valor entre 0 e 1
```

### Modificando a Frequ√™ncia de Resumos

Para alterar a frequ√™ncia com que as descri√ß√µes s√£o geradas:

```python
if current_time - last_caption_time > 10:  # Altere o intervalo em segundos
```

### Selecionando Classes de Interesse

Para focar em categorias espec√≠ficas, modifique a verifica√ß√£o de objetos importantes:

```python
has_important_objects = any(obj in ['person', 'car', 'truck', 'bus'] for obj in obj_counts.keys())
# Adicione ou remova classes conforme necess√°rio
```

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Por favor, siga estas etapas:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Fa√ßa commit das altera√ß√µes (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìù TODO

- [ ] Adicionar suporte para processamento em GPU via CUDA
- [ ] Implementar tracking de objetos entre frames
- [ ] Desenvolver uma API REST para integra√ß√£o com outros sistemas
- [ ] Adicionar suporte para m√∫ltiplas c√¢meras
- [ ] Criar visualiza√ß√µes estat√≠sticas dos objetos detectados

## üìñ Cita√ß√µes

Se utilizar este projeto em pesquisas acad√™micas, por favor cite:

```
@software{yolo_icm_2025,
  author = {The Luffy Rossa},
  title = {YOLO-ICM: Sistema Integrado de Detec√ß√£o de Objetos e Gera√ß√£o de Resumos de Imagens},
  url = {https://github.com/theluffyrossa/yolo-icm},
  year = {2025},
}
```


## üôè Agradecimentos

- [AlexeyAB](https://github.com/AlexeyAB/darknet) pelo desenvolvimento do YOLOv4
- [Salesforce Research](https://github.com/salesforce/BLIP) pelo modelo BLIP
- Todos os contribuidores e testadores

---

Desenvolvido por [theluffyrossa](https://github.com/theluffyrossa) - 2025
